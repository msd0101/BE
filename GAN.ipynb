{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "image_size = 28 * 28\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:02<00:00, 3.53MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.56MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 4.51MB/s]\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            \n",
    "            nn.Linear(1024, image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(-1, image_size)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "real_accuracies = []\n",
    "fake_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/50] [Batch 0/938] [D loss: 0.6918] [G loss: 0.6726] [Real acc: 0.8438] [Fake acc: 0.1250]\n",
      "[Epoch 0/50] [Batch 100/938] [D loss: 0.2058] [G loss: 2.2216] [Real acc: 0.9531] [Fake acc: 1.0000]\n",
      "[Epoch 0/50] [Batch 200/938] [D loss: 0.2875] [G loss: 1.3182] [Real acc: 0.9844] [Fake acc: 0.9844]\n",
      "[Epoch 0/50] [Batch 300/938] [D loss: 0.7937] [G loss: 0.2495] [Real acc: 1.0000] [Fake acc: 0.0000]\n",
      "[Epoch 0/50] [Batch 400/938] [D loss: 0.5080] [G loss: 1.0084] [Real acc: 0.7500] [Fake acc: 0.9844]\n",
      "[Epoch 0/50] [Batch 500/938] [D loss: 0.6411] [G loss: 1.0729] [Real acc: 0.2969] [Fake acc: 1.0000]\n",
      "[Epoch 0/50] [Batch 600/938] [D loss: 0.6236] [G loss: 0.5991] [Real acc: 0.9844] [Fake acc: 0.1094]\n",
      "[Epoch 0/50] [Batch 700/938] [D loss: 0.6171] [G loss: 0.6879] [Real acc: 0.8906] [Fake acc: 0.4219]\n",
      "[Epoch 0/50] [Batch 800/938] [D loss: 0.6266] [G loss: 0.5337] [Real acc: 1.0000] [Fake acc: 0.0781]\n",
      "[Epoch 0/50] [Batch 900/938] [D loss: 0.7551] [G loss: 1.4326] [Real acc: 0.0625] [Fake acc: 1.0000]\n",
      "[Epoch 0/50] [D loss: 0.5289] [G loss: 0.9451] [D real acc: 0.8114] [D fake acc: 0.6599]\n",
      "[Epoch 1/50] [Batch 0/938] [D loss: 0.6379] [G loss: 0.8938] [Real acc: 0.4688] [Fake acc: 0.9688]\n",
      "[Epoch 1/50] [Batch 100/938] [D loss: 0.6596] [G loss: 0.6342] [Real acc: 0.8281] [Fake acc: 0.2344]\n",
      "[Epoch 1/50] [Batch 200/938] [D loss: 0.6156] [G loss: 0.8004] [Real acc: 0.6875] [Fake acc: 0.7500]\n",
      "[Epoch 1/50] [Batch 300/938] [D loss: 0.6383] [G loss: 0.8030] [Real acc: 0.6562] [Fake acc: 0.8281]\n",
      "[Epoch 1/50] [Batch 400/938] [D loss: 0.6448] [G loss: 0.6218] [Real acc: 0.8594] [Fake acc: 0.2969]\n",
      "[Epoch 1/50] [Batch 500/938] [D loss: 0.6169] [G loss: 0.7710] [Real acc: 0.7031] [Fake acc: 0.6719]\n",
      "[Epoch 1/50] [Batch 600/938] [D loss: 0.6254] [G loss: 0.7927] [Real acc: 0.6719] [Fake acc: 0.7188]\n",
      "[Epoch 1/50] [Batch 700/938] [D loss: 0.5845] [G loss: 0.9301] [Real acc: 0.5312] [Fake acc: 0.9531]\n",
      "[Epoch 1/50] [Batch 800/938] [D loss: 0.6500] [G loss: 0.6567] [Real acc: 0.7344] [Fake acc: 0.4219]\n",
      "[Epoch 1/50] [Batch 900/938] [D loss: 0.6348] [G loss: 0.6970] [Real acc: 0.7500] [Fake acc: 0.5156]\n",
      "[Epoch 1/50] [D loss: 0.6372] [G loss: 0.7984] [D real acc: 0.6523] [D fake acc: 0.6450]\n",
      "[Epoch 2/50] [Batch 0/938] [D loss: 0.6353] [G loss: 0.8237] [Real acc: 0.5625] [Fake acc: 0.7500]\n",
      "[Epoch 2/50] [Batch 100/938] [D loss: 0.6040] [G loss: 0.8509] [Real acc: 0.6719] [Fake acc: 0.7812]\n",
      "[Epoch 2/50] [Batch 200/938] [D loss: 0.6518] [G loss: 1.0385] [Real acc: 0.3438] [Fake acc: 0.9375]\n",
      "[Epoch 2/50] [Batch 300/938] [D loss: 0.7203] [G loss: 1.3509] [Real acc: 0.1250] [Fake acc: 0.9844]\n",
      "[Epoch 2/50] [Batch 400/938] [D loss: 0.5952] [G loss: 0.8065] [Real acc: 0.7812] [Fake acc: 0.6875]\n",
      "[Epoch 2/50] [Batch 500/938] [D loss: 0.6235] [G loss: 0.7711] [Real acc: 0.6719] [Fake acc: 0.6719]\n",
      "[Epoch 2/50] [Batch 600/938] [D loss: 0.6270] [G loss: 0.5918] [Real acc: 0.8750] [Fake acc: 0.2344]\n",
      "[Epoch 2/50] [Batch 700/938] [D loss: 0.6055] [G loss: 0.7628] [Real acc: 0.7188] [Fake acc: 0.6719]\n",
      "[Epoch 2/50] [Batch 800/938] [D loss: 0.6440] [G loss: 0.6719] [Real acc: 0.8125] [Fake acc: 0.4844]\n",
      "[Epoch 2/50] [Batch 900/938] [D loss: 0.6576] [G loss: 0.7944] [Real acc: 0.5469] [Fake acc: 0.6562]\n",
      "[Epoch 2/50] [D loss: 0.6405] [G loss: 0.8056] [D real acc: 0.6353] [D fake acc: 0.6511]\n",
      "[Epoch 3/50] [Batch 0/938] [D loss: 0.6952] [G loss: 1.2018] [Real acc: 0.1250] [Fake acc: 0.9531]\n",
      "[Epoch 3/50] [Batch 100/938] [D loss: 0.6564] [G loss: 0.7179] [Real acc: 0.6562] [Fake acc: 0.6094]\n",
      "[Epoch 3/50] [Batch 200/938] [D loss: 0.7043] [G loss: 0.8929] [Real acc: 0.2188] [Fake acc: 0.8125]\n",
      "[Epoch 3/50] [Batch 300/938] [D loss: 0.6382] [G loss: 0.8766] [Real acc: 0.5312] [Fake acc: 0.8281]\n",
      "[Epoch 3/50] [Batch 400/938] [D loss: 0.6466] [G loss: 0.7998] [Real acc: 0.5781] [Fake acc: 0.7031]\n",
      "[Epoch 3/50] [Batch 500/938] [D loss: 0.6215] [G loss: 0.8573] [Real acc: 0.5625] [Fake acc: 0.7031]\n",
      "[Epoch 3/50] [Batch 600/938] [D loss: 0.7003] [G loss: 0.4982] [Real acc: 0.9219] [Fake acc: 0.0625]\n",
      "[Epoch 3/50] [Batch 700/938] [D loss: 0.6405] [G loss: 0.9546] [Real acc: 0.3906] [Fake acc: 0.9219]\n",
      "[Epoch 3/50] [Batch 800/938] [D loss: 0.6536] [G loss: 0.6217] [Real acc: 0.8750] [Fake acc: 0.3906]\n",
      "[Epoch 3/50] [Batch 900/938] [D loss: 0.6508] [G loss: 0.8005] [Real acc: 0.5156] [Fake acc: 0.6562]\n",
      "[Epoch 3/50] [D loss: 0.6521] [G loss: 0.7849] [D real acc: 0.6176] [D fake acc: 0.6244]\n",
      "[Epoch 4/50] [Batch 0/938] [D loss: 0.6416] [G loss: 0.8058] [Real acc: 0.5781] [Fake acc: 0.6719]\n",
      "[Epoch 4/50] [Batch 100/938] [D loss: 0.6700] [G loss: 0.5753] [Real acc: 0.9219] [Fake acc: 0.2031]\n",
      "[Epoch 4/50] [Batch 200/938] [D loss: 0.6533] [G loss: 0.8597] [Real acc: 0.3906] [Fake acc: 0.7969]\n",
      "[Epoch 4/50] [Batch 300/938] [D loss: 0.6414] [G loss: 0.6672] [Real acc: 0.8594] [Fake acc: 0.3906]\n",
      "[Epoch 4/50] [Batch 400/938] [D loss: 0.6460] [G loss: 0.8630] [Real acc: 0.4844] [Fake acc: 0.8594]\n",
      "[Epoch 4/50] [Batch 500/938] [D loss: 0.6341] [G loss: 0.8339] [Real acc: 0.6250] [Fake acc: 0.7812]\n",
      "[Epoch 4/50] [Batch 600/938] [D loss: 0.6274] [G loss: 0.7654] [Real acc: 0.6406] [Fake acc: 0.6094]\n",
      "[Epoch 4/50] [Batch 700/938] [D loss: 0.6336] [G loss: 0.7889] [Real acc: 0.6719] [Fake acc: 0.7031]\n",
      "[Epoch 4/50] [Batch 800/938] [D loss: 0.7025] [G loss: 1.1791] [Real acc: 0.1562] [Fake acc: 1.0000]\n",
      "[Epoch 4/50] [Batch 900/938] [D loss: 0.6595] [G loss: 0.9996] [Real acc: 0.2500] [Fake acc: 0.9219]\n",
      "[Epoch 4/50] [D loss: 0.6535] [G loss: 0.7824] [D real acc: 0.6147] [D fake acc: 0.6199]\n",
      "[Epoch 5/50] [Batch 0/938] [D loss: 0.6392] [G loss: 0.9145] [Real acc: 0.4062] [Fake acc: 0.8906]\n",
      "[Epoch 5/50] [Batch 100/938] [D loss: 0.6295] [G loss: 0.8062] [Real acc: 0.6719] [Fake acc: 0.7188]\n",
      "[Epoch 5/50] [Batch 200/938] [D loss: 0.6415] [G loss: 0.6900] [Real acc: 0.7969] [Fake acc: 0.4375]\n",
      "[Epoch 5/50] [Batch 300/938] [D loss: 0.6263] [G loss: 0.7316] [Real acc: 0.7188] [Fake acc: 0.5781]\n",
      "[Epoch 5/50] [Batch 400/938] [D loss: 0.6605] [G loss: 0.6171] [Real acc: 0.8906] [Fake acc: 0.4219]\n",
      "[Epoch 5/50] [Batch 500/938] [D loss: 0.6544] [G loss: 0.7565] [Real acc: 0.5938] [Fake acc: 0.5938]\n",
      "[Epoch 5/50] [Batch 600/938] [D loss: 0.6559] [G loss: 0.6775] [Real acc: 0.8125] [Fake acc: 0.4375]\n",
      "[Epoch 5/50] [Batch 700/938] [D loss: 0.6531] [G loss: 0.5796] [Real acc: 0.9219] [Fake acc: 0.2656]\n",
      "[Epoch 5/50] [Batch 800/938] [D loss: 0.6184] [G loss: 0.7528] [Real acc: 0.7969] [Fake acc: 0.6250]\n",
      "[Epoch 5/50] [Batch 900/938] [D loss: 0.6328] [G loss: 0.6637] [Real acc: 0.8594] [Fake acc: 0.4688]\n",
      "[Epoch 5/50] [D loss: 0.6527] [G loss: 0.7874] [D real acc: 0.6145] [D fake acc: 0.6249]\n",
      "[Epoch 6/50] [Batch 0/938] [D loss: 0.8020] [G loss: 0.3340] [Real acc: 0.9844] [Fake acc: 0.0000]\n",
      "[Epoch 6/50] [Batch 100/938] [D loss: 0.6369] [G loss: 0.7786] [Real acc: 0.7188] [Fake acc: 0.6875]\n",
      "[Epoch 6/50] [Batch 200/938] [D loss: 0.6476] [G loss: 0.9848] [Real acc: 0.3281] [Fake acc: 0.9219]\n",
      "[Epoch 6/50] [Batch 300/938] [D loss: 0.6647] [G loss: 0.9159] [Real acc: 0.3125] [Fake acc: 0.8438]\n",
      "[Epoch 6/50] [Batch 400/938] [D loss: 0.6370] [G loss: 0.8049] [Real acc: 0.6094] [Fake acc: 0.7344]\n",
      "[Epoch 6/50] [Batch 500/938] [D loss: 0.7056] [G loss: 0.5253] [Real acc: 0.8594] [Fake acc: 0.1562]\n",
      "[Epoch 6/50] [Batch 600/938] [D loss: 0.6373] [G loss: 0.8662] [Real acc: 0.5469] [Fake acc: 0.7500]\n",
      "[Epoch 6/50] [Batch 700/938] [D loss: 0.6534] [G loss: 0.9658] [Real acc: 0.4219] [Fake acc: 0.8750]\n",
      "[Epoch 6/50] [Batch 800/938] [D loss: 0.6768] [G loss: 0.5789] [Real acc: 0.8438] [Fake acc: 0.1250]\n",
      "[Epoch 6/50] [Batch 900/938] [D loss: 0.6964] [G loss: 1.1008] [Real acc: 0.1875] [Fake acc: 0.9844]\n",
      "[Epoch 6/50] [D loss: 0.6512] [G loss: 0.7919] [D real acc: 0.6162] [D fake acc: 0.6265]\n",
      "[Epoch 7/50] [Batch 0/938] [D loss: 0.6591] [G loss: 0.8796] [Real acc: 0.4531] [Fake acc: 0.7656]\n",
      "[Epoch 7/50] [Batch 100/938] [D loss: 0.6556] [G loss: 0.8264] [Real acc: 0.5469] [Fake acc: 0.7188]\n",
      "[Epoch 7/50] [Batch 200/938] [D loss: 0.6464] [G loss: 0.9996] [Real acc: 0.3125] [Fake acc: 0.9062]\n",
      "[Epoch 7/50] [Batch 300/938] [D loss: 0.6058] [G loss: 0.8506] [Real acc: 0.6875] [Fake acc: 0.7344]\n",
      "[Epoch 7/50] [Batch 400/938] [D loss: 0.6808] [G loss: 0.9907] [Real acc: 0.2969] [Fake acc: 0.8125]\n",
      "[Epoch 7/50] [Batch 500/938] [D loss: 0.6264] [G loss: 0.8277] [Real acc: 0.5781] [Fake acc: 0.7812]\n",
      "[Epoch 7/50] [Batch 600/938] [D loss: 0.6371] [G loss: 0.7596] [Real acc: 0.6406] [Fake acc: 0.5625]\n",
      "[Epoch 7/50] [Batch 700/938] [D loss: 0.6433] [G loss: 0.7532] [Real acc: 0.6719] [Fake acc: 0.6875]\n",
      "[Epoch 7/50] [Batch 800/938] [D loss: 0.6625] [G loss: 0.9431] [Real acc: 0.2812] [Fake acc: 0.8594]\n",
      "[Epoch 7/50] [Batch 900/938] [D loss: 0.6192] [G loss: 0.6841] [Real acc: 0.9219] [Fake acc: 0.4375]\n",
      "[Epoch 7/50] [D loss: 0.6503] [G loss: 0.7949] [D real acc: 0.6165] [D fake acc: 0.6276]\n",
      "[Epoch 8/50] [Batch 0/938] [D loss: 0.6402] [G loss: 0.8505] [Real acc: 0.5469] [Fake acc: 0.7812]\n",
      "[Epoch 8/50] [Batch 100/938] [D loss: 0.6157] [G loss: 0.7710] [Real acc: 0.7031] [Fake acc: 0.6719]\n",
      "[Epoch 8/50] [Batch 200/938] [D loss: 0.6344] [G loss: 0.8331] [Real acc: 0.6562] [Fake acc: 0.6875]\n",
      "[Epoch 8/50] [Batch 300/938] [D loss: 0.6390] [G loss: 0.6221] [Real acc: 0.8750] [Fake acc: 0.3438]\n",
      "[Epoch 8/50] [Batch 400/938] [D loss: 0.6212] [G loss: 0.8289] [Real acc: 0.6094] [Fake acc: 0.7031]\n",
      "[Epoch 8/50] [Batch 500/938] [D loss: 0.6310] [G loss: 0.8467] [Real acc: 0.5469] [Fake acc: 0.7656]\n",
      "[Epoch 8/50] [Batch 600/938] [D loss: 0.6515] [G loss: 0.8037] [Real acc: 0.6094] [Fake acc: 0.6250]\n",
      "[Epoch 8/50] [Batch 700/938] [D loss: 0.6329] [G loss: 0.8229] [Real acc: 0.5625] [Fake acc: 0.6562]\n",
      "[Epoch 8/50] [Batch 800/938] [D loss: 0.6652] [G loss: 0.9442] [Real acc: 0.3906] [Fake acc: 0.8281]\n",
      "[Epoch 8/50] [Batch 900/938] [D loss: 0.6577] [G loss: 0.8217] [Real acc: 0.5938] [Fake acc: 0.6875]\n",
      "[Epoch 8/50] [D loss: 0.6507] [G loss: 0.7969] [D real acc: 0.6163] [D fake acc: 0.6273]\n",
      "[Epoch 9/50] [Batch 0/938] [D loss: 0.6914] [G loss: 0.5367] [Real acc: 0.9375] [Fake acc: 0.2031]\n",
      "[Epoch 9/50] [Batch 100/938] [D loss: 0.6047] [G loss: 0.7946] [Real acc: 0.8281] [Fake acc: 0.7188]\n",
      "[Epoch 9/50] [Batch 200/938] [D loss: 0.6425] [G loss: 0.8941] [Real acc: 0.4219] [Fake acc: 0.9062]\n",
      "[Epoch 9/50] [Batch 300/938] [D loss: 0.6519] [G loss: 0.9214] [Real acc: 0.3594] [Fake acc: 0.8594]\n",
      "[Epoch 9/50] [Batch 400/938] [D loss: 0.6472] [G loss: 0.8302] [Real acc: 0.5312] [Fake acc: 0.7500]\n",
      "[Epoch 9/50] [Batch 500/938] [D loss: 0.6632] [G loss: 0.6994] [Real acc: 0.7344] [Fake acc: 0.4219]\n",
      "[Epoch 9/50] [Batch 600/938] [D loss: 0.6387] [G loss: 0.8958] [Real acc: 0.4844] [Fake acc: 0.8281]\n",
      "[Epoch 9/50] [Batch 700/938] [D loss: 0.6721] [G loss: 0.7769] [Real acc: 0.4688] [Fake acc: 0.7031]\n",
      "[Epoch 9/50] [Batch 800/938] [D loss: 0.6380] [G loss: 0.8999] [Real acc: 0.4375] [Fake acc: 0.7812]\n",
      "[Epoch 9/50] [Batch 900/938] [D loss: 0.6294] [G loss: 0.8821] [Real acc: 0.6250] [Fake acc: 0.7812]\n",
      "[Epoch 9/50] [D loss: 0.6515] [G loss: 0.7945] [D real acc: 0.6114] [D fake acc: 0.6260]\n",
      "[Epoch 10/50] [Batch 0/938] [D loss: 0.6457] [G loss: 0.9057] [Real acc: 0.4531] [Fake acc: 0.8594]\n",
      "[Epoch 10/50] [Batch 100/938] [D loss: 0.6897] [G loss: 0.8184] [Real acc: 0.4219] [Fake acc: 0.7188]\n",
      "[Epoch 10/50] [Batch 200/938] [D loss: 0.6731] [G loss: 0.5821] [Real acc: 0.9219] [Fake acc: 0.2500]\n",
      "[Epoch 10/50] [Batch 300/938] [D loss: 0.6657] [G loss: 0.8828] [Real acc: 0.3594] [Fake acc: 0.7656]\n",
      "[Epoch 10/50] [Batch 400/938] [D loss: 0.6367] [G loss: 0.7168] [Real acc: 0.7188] [Fake acc: 0.5312]\n",
      "[Epoch 10/50] [Batch 500/938] [D loss: 0.7083] [G loss: 1.2061] [Real acc: 0.1094] [Fake acc: 0.9531]\n",
      "[Epoch 10/50] [Batch 600/938] [D loss: 0.6558] [G loss: 0.9160] [Real acc: 0.3438] [Fake acc: 0.8281]\n",
      "[Epoch 10/50] [Batch 700/938] [D loss: 0.6365] [G loss: 0.6518] [Real acc: 0.9219] [Fake acc: 0.3594]\n",
      "[Epoch 10/50] [Batch 800/938] [D loss: 0.6637] [G loss: 0.9561] [Real acc: 0.3594] [Fake acc: 0.9062]\n",
      "[Epoch 10/50] [Batch 900/938] [D loss: 0.6468] [G loss: 0.8677] [Real acc: 0.3906] [Fake acc: 0.8125]\n",
      "[Epoch 10/50] [D loss: 0.6520] [G loss: 0.7967] [D real acc: 0.6121] [D fake acc: 0.6234]\n",
      "[Epoch 11/50] [Batch 0/938] [D loss: 0.6561] [G loss: 0.6529] [Real acc: 0.7969] [Fake acc: 0.3594]\n",
      "[Epoch 11/50] [Batch 100/938] [D loss: 0.6529] [G loss: 0.6614] [Real acc: 0.8125] [Fake acc: 0.4375]\n",
      "[Epoch 11/50] [Batch 200/938] [D loss: 0.6742] [G loss: 0.7301] [Real acc: 0.6406] [Fake acc: 0.5312]\n",
      "[Epoch 11/50] [Batch 300/938] [D loss: 0.6309] [G loss: 0.9928] [Real acc: 0.4375] [Fake acc: 0.7969]\n",
      "[Epoch 11/50] [Batch 400/938] [D loss: 0.6497] [G loss: 0.7865] [Real acc: 0.5312] [Fake acc: 0.6406]\n",
      "[Epoch 11/50] [Batch 500/938] [D loss: 0.6197] [G loss: 0.9346] [Real acc: 0.4531] [Fake acc: 0.8594]\n",
      "[Epoch 11/50] [Batch 600/938] [D loss: 0.6434] [G loss: 0.6775] [Real acc: 0.8281] [Fake acc: 0.4688]\n",
      "[Epoch 11/50] [Batch 700/938] [D loss: 0.6292] [G loss: 0.7719] [Real acc: 0.6250] [Fake acc: 0.6250]\n",
      "[Epoch 11/50] [Batch 800/938] [D loss: 0.6687] [G loss: 0.6901] [Real acc: 0.6875] [Fake acc: 0.5000]\n",
      "[Epoch 11/50] [Batch 900/938] [D loss: 0.6291] [G loss: 0.7753] [Real acc: 0.6719] [Fake acc: 0.6250]\n",
      "[Epoch 11/50] [D loss: 0.6501] [G loss: 0.7995] [D real acc: 0.6149] [D fake acc: 0.6310]\n",
      "[Epoch 12/50] [Batch 0/938] [D loss: 0.6682] [G loss: 1.0254] [Real acc: 0.3281] [Fake acc: 0.8750]\n",
      "[Epoch 12/50] [Batch 100/938] [D loss: 0.6138] [G loss: 0.8949] [Real acc: 0.5938] [Fake acc: 0.8438]\n",
      "[Epoch 12/50] [Batch 200/938] [D loss: 0.6482] [G loss: 0.6465] [Real acc: 0.9062] [Fake acc: 0.4219]\n",
      "[Epoch 12/50] [Batch 300/938] [D loss: 0.6280] [G loss: 0.7448] [Real acc: 0.7656] [Fake acc: 0.5625]\n",
      "[Epoch 12/50] [Batch 400/938] [D loss: 0.6361] [G loss: 0.7145] [Real acc: 0.7500] [Fake acc: 0.4844]\n",
      "[Epoch 12/50] [Batch 500/938] [D loss: 0.6164] [G loss: 0.8256] [Real acc: 0.6094] [Fake acc: 0.6562]\n",
      "[Epoch 12/50] [Batch 600/938] [D loss: 0.6515] [G loss: 0.8125] [Real acc: 0.5625] [Fake acc: 0.6406]\n",
      "[Epoch 12/50] [Batch 700/938] [D loss: 0.6409] [G loss: 0.6516] [Real acc: 0.8750] [Fake acc: 0.3594]\n",
      "[Epoch 12/50] [Batch 800/938] [D loss: 0.6671] [G loss: 0.7715] [Real acc: 0.5938] [Fake acc: 0.6250]\n",
      "[Epoch 12/50] [Batch 900/938] [D loss: 0.7495] [G loss: 0.3869] [Real acc: 1.0000] [Fake acc: 0.0000]\n",
      "[Epoch 12/50] [D loss: 0.6481] [G loss: 0.8055] [D real acc: 0.6139] [D fake acc: 0.6335]\n",
      "[Epoch 13/50] [Batch 0/938] [D loss: 0.6296] [G loss: 0.8174] [Real acc: 0.6719] [Fake acc: 0.6719]\n",
      "[Epoch 13/50] [Batch 100/938] [D loss: 0.7030] [G loss: 0.4841] [Real acc: 0.9531] [Fake acc: 0.1719]\n",
      "[Epoch 13/50] [Batch 200/938] [D loss: 0.6457] [G loss: 0.9935] [Real acc: 0.3594] [Fake acc: 0.9375]\n",
      "[Epoch 13/50] [Batch 300/938] [D loss: 0.6827] [G loss: 1.3157] [Real acc: 0.1406] [Fake acc: 0.9844]\n",
      "[Epoch 13/50] [Batch 400/938] [D loss: 0.6615] [G loss: 0.6943] [Real acc: 0.7188] [Fake acc: 0.4688]\n",
      "[Epoch 13/50] [Batch 500/938] [D loss: 0.6156] [G loss: 0.7273] [Real acc: 0.8125] [Fake acc: 0.4844]\n",
      "[Epoch 13/50] [Batch 600/938] [D loss: 0.6400] [G loss: 0.8952] [Real acc: 0.4219] [Fake acc: 0.7656]\n",
      "[Epoch 13/50] [Batch 700/938] [D loss: 0.6293] [G loss: 0.7377] [Real acc: 0.7656] [Fake acc: 0.5000]\n",
      "[Epoch 13/50] [Batch 800/938] [D loss: 0.6803] [G loss: 0.9715] [Real acc: 0.2812] [Fake acc: 0.8281]\n",
      "[Epoch 13/50] [Batch 900/938] [D loss: 0.6239] [G loss: 0.7164] [Real acc: 0.7969] [Fake acc: 0.4844]\n",
      "[Epoch 13/50] [D loss: 0.6453] [G loss: 0.8120] [D real acc: 0.6137] [D fake acc: 0.6359]\n",
      "[Epoch 14/50] [Batch 0/938] [D loss: 0.6316] [G loss: 0.7056] [Real acc: 0.8438] [Fake acc: 0.5312]\n",
      "[Epoch 14/50] [Batch 100/938] [D loss: 0.6465] [G loss: 0.9580] [Real acc: 0.3750] [Fake acc: 0.9531]\n",
      "[Epoch 14/50] [Batch 200/938] [D loss: 0.6396] [G loss: 0.8033] [Real acc: 0.6406] [Fake acc: 0.6094]\n",
      "[Epoch 14/50] [Batch 300/938] [D loss: 0.6219] [G loss: 0.7631] [Real acc: 0.7344] [Fake acc: 0.5625]\n",
      "[Epoch 14/50] [Batch 400/938] [D loss: 0.6281] [G loss: 0.7199] [Real acc: 0.7969] [Fake acc: 0.5781]\n",
      "[Epoch 14/50] [Batch 500/938] [D loss: 0.6847] [G loss: 0.9352] [Real acc: 0.3594] [Fake acc: 0.7969]\n",
      "[Epoch 14/50] [Batch 600/938] [D loss: 0.6220] [G loss: 0.7887] [Real acc: 0.6875] [Fake acc: 0.6406]\n",
      "[Epoch 14/50] [Batch 700/938] [D loss: 0.6341] [G loss: 0.8541] [Real acc: 0.5312] [Fake acc: 0.7812]\n",
      "[Epoch 14/50] [Batch 800/938] [D loss: 0.6722] [G loss: 0.6609] [Real acc: 0.7500] [Fake acc: 0.3438]\n",
      "[Epoch 14/50] [Batch 900/938] [D loss: 0.6108] [G loss: 0.8914] [Real acc: 0.5469] [Fake acc: 0.8281]\n",
      "[Epoch 14/50] [D loss: 0.6442] [G loss: 0.8176] [D real acc: 0.6162] [D fake acc: 0.6367]\n",
      "[Epoch 15/50] [Batch 0/938] [D loss: 0.6360] [G loss: 0.9166] [Real acc: 0.5625] [Fake acc: 0.7812]\n",
      "[Epoch 15/50] [Batch 100/938] [D loss: 0.6237] [G loss: 0.7670] [Real acc: 0.7344] [Fake acc: 0.6094]\n",
      "[Epoch 15/50] [Batch 200/938] [D loss: 0.6031] [G loss: 0.7724] [Real acc: 0.8281] [Fake acc: 0.5781]\n",
      "[Epoch 15/50] [Batch 300/938] [D loss: 0.6753] [G loss: 1.1318] [Real acc: 0.2344] [Fake acc: 0.9688]\n",
      "[Epoch 15/50] [Batch 400/938] [D loss: 0.6322] [G loss: 0.7600] [Real acc: 0.7500] [Fake acc: 0.5625]\n",
      "[Epoch 15/50] [Batch 500/938] [D loss: 0.6406] [G loss: 0.9953] [Real acc: 0.4062] [Fake acc: 0.8594]\n",
      "[Epoch 15/50] [Batch 600/938] [D loss: 0.6372] [G loss: 1.0118] [Real acc: 0.3594] [Fake acc: 0.8125]\n",
      "[Epoch 15/50] [Batch 700/938] [D loss: 0.6395] [G loss: 1.1082] [Real acc: 0.2656] [Fake acc: 0.9688]\n",
      "[Epoch 15/50] [Batch 800/938] [D loss: 0.6073] [G loss: 0.7200] [Real acc: 0.9375] [Fake acc: 0.4062]\n",
      "[Epoch 15/50] [Batch 900/938] [D loss: 0.6472] [G loss: 0.9797] [Real acc: 0.4062] [Fake acc: 0.8281]\n",
      "[Epoch 15/50] [D loss: 0.6423] [G loss: 0.8242] [D real acc: 0.6214] [D fake acc: 0.6360]\n",
      "[Epoch 16/50] [Batch 0/938] [D loss: 0.5897] [G loss: 0.8807] [Real acc: 0.7188] [Fake acc: 0.7812]\n",
      "[Epoch 16/50] [Batch 100/938] [D loss: 0.6490] [G loss: 0.9944] [Real acc: 0.4688] [Fake acc: 0.8281]\n",
      "[Epoch 16/50] [Batch 200/938] [D loss: 0.6261] [G loss: 0.7404] [Real acc: 0.8750] [Fake acc: 0.5781]\n",
      "[Epoch 16/50] [Batch 300/938] [D loss: 0.6218] [G loss: 0.7222] [Real acc: 0.8125] [Fake acc: 0.5312]\n",
      "[Epoch 16/50] [Batch 400/938] [D loss: 0.6325] [G loss: 0.9908] [Real acc: 0.3750] [Fake acc: 0.7969]\n",
      "[Epoch 16/50] [Batch 500/938] [D loss: 0.6298] [G loss: 1.0188] [Real acc: 0.4062] [Fake acc: 0.8750]\n",
      "[Epoch 16/50] [Batch 600/938] [D loss: 0.6226] [G loss: 0.8943] [Real acc: 0.5781] [Fake acc: 0.8281]\n",
      "[Epoch 16/50] [Batch 700/938] [D loss: 0.7621] [G loss: 0.4044] [Real acc: 0.9219] [Fake acc: 0.0781]\n",
      "[Epoch 16/50] [Batch 800/938] [D loss: 0.7233] [G loss: 0.4254] [Real acc: 0.9688] [Fake acc: 0.0938]\n",
      "[Epoch 16/50] [Batch 900/938] [D loss: 0.6514] [G loss: 0.8989] [Real acc: 0.4375] [Fake acc: 0.7969]\n",
      "[Epoch 16/50] [D loss: 0.6408] [G loss: 0.8293] [D real acc: 0.6229] [D fake acc: 0.6416]\n",
      "[Epoch 17/50] [Batch 0/938] [D loss: 0.6950] [G loss: 0.5108] [Real acc: 0.9531] [Fake acc: 0.1250]\n",
      "[Epoch 17/50] [Batch 100/938] [D loss: 0.6325] [G loss: 0.7727] [Real acc: 0.7344] [Fake acc: 0.5625]\n",
      "[Epoch 17/50] [Batch 200/938] [D loss: 0.6558] [G loss: 0.6739] [Real acc: 0.7500] [Fake acc: 0.4219]\n",
      "[Epoch 17/50] [Batch 300/938] [D loss: 0.6617] [G loss: 0.8364] [Real acc: 0.5469] [Fake acc: 0.6562]\n",
      "[Epoch 17/50] [Batch 400/938] [D loss: 0.7471] [G loss: 1.3552] [Real acc: 0.0938] [Fake acc: 0.9844]\n",
      "[Epoch 17/50] [Batch 500/938] [D loss: 0.6664] [G loss: 0.5741] [Real acc: 0.8906] [Fake acc: 0.1875]\n",
      "[Epoch 17/50] [Batch 600/938] [D loss: 0.6437] [G loss: 0.6446] [Real acc: 0.8750] [Fake acc: 0.3438]\n",
      "[Epoch 17/50] [Batch 700/938] [D loss: 0.6519] [G loss: 0.8630] [Real acc: 0.4531] [Fake acc: 0.7656]\n",
      "[Epoch 17/50] [Batch 800/938] [D loss: 0.6537] [G loss: 0.9608] [Real acc: 0.3438] [Fake acc: 0.9219]\n",
      "[Epoch 17/50] [Batch 900/938] [D loss: 0.6681] [G loss: 0.8828] [Real acc: 0.4219] [Fake acc: 0.7031]\n",
      "[Epoch 17/50] [D loss: 0.6387] [G loss: 0.8362] [D real acc: 0.6254] [D fake acc: 0.6441]\n",
      "[Epoch 18/50] [Batch 0/938] [D loss: 0.6026] [G loss: 0.8900] [Real acc: 0.6250] [Fake acc: 0.7656]\n",
      "[Epoch 18/50] [Batch 100/938] [D loss: 0.7090] [G loss: 1.3811] [Real acc: 0.0938] [Fake acc: 0.9531]\n",
      "[Epoch 18/50] [Batch 200/938] [D loss: 0.6222] [G loss: 0.6636] [Real acc: 0.8906] [Fake acc: 0.3906]\n",
      "[Epoch 18/50] [Batch 300/938] [D loss: 0.6522] [G loss: 0.6745] [Real acc: 0.7500] [Fake acc: 0.4219]\n",
      "[Epoch 18/50] [Batch 400/938] [D loss: 0.5930] [G loss: 0.8884] [Real acc: 0.6562] [Fake acc: 0.7500]\n",
      "[Epoch 18/50] [Batch 500/938] [D loss: 0.6458] [G loss: 0.7242] [Real acc: 0.7812] [Fake acc: 0.4375]\n",
      "[Epoch 18/50] [Batch 600/938] [D loss: 0.6787] [G loss: 0.9765] [Real acc: 0.3594] [Fake acc: 0.7344]\n",
      "[Epoch 18/50] [Batch 700/938] [D loss: 0.6393] [G loss: 0.9563] [Real acc: 0.4531] [Fake acc: 0.7812]\n",
      "[Epoch 18/50] [Batch 800/938] [D loss: 0.6201] [G loss: 0.9014] [Real acc: 0.5312] [Fake acc: 0.7344]\n",
      "[Epoch 18/50] [Batch 900/938] [D loss: 0.5786] [G loss: 0.8151] [Real acc: 0.8750] [Fake acc: 0.6719]\n",
      "[Epoch 18/50] [D loss: 0.6364] [G loss: 0.8413] [D real acc: 0.6262] [D fake acc: 0.6477]\n",
      "[Epoch 19/50] [Batch 0/938] [D loss: 0.6502] [G loss: 0.6661] [Real acc: 0.8438] [Fake acc: 0.3125]\n",
      "[Epoch 19/50] [Batch 100/938] [D loss: 0.6600] [G loss: 0.6268] [Real acc: 0.8750] [Fake acc: 0.3750]\n",
      "[Epoch 19/50] [Batch 200/938] [D loss: 0.6355] [G loss: 0.6134] [Real acc: 0.9219] [Fake acc: 0.3594]\n",
      "[Epoch 19/50] [Batch 300/938] [D loss: 0.6499] [G loss: 0.9196] [Real acc: 0.4531] [Fake acc: 0.8594]\n",
      "[Epoch 19/50] [Batch 400/938] [D loss: 0.6334] [G loss: 1.1052] [Real acc: 0.2969] [Fake acc: 0.8750]\n",
      "[Epoch 19/50] [Batch 500/938] [D loss: 0.6446] [G loss: 0.9935] [Real acc: 0.3750] [Fake acc: 0.8438]\n",
      "[Epoch 19/50] [Batch 600/938] [D loss: 0.6627] [G loss: 0.7036] [Real acc: 0.7344] [Fake acc: 0.4688]\n",
      "[Epoch 19/50] [Batch 700/938] [D loss: 0.6160] [G loss: 0.7509] [Real acc: 0.8125] [Fake acc: 0.5156]\n",
      "[Epoch 19/50] [Batch 800/938] [D loss: 0.6349] [G loss: 0.9129] [Real acc: 0.5625] [Fake acc: 0.7969]\n",
      "[Epoch 19/50] [Batch 900/938] [D loss: 0.6274] [G loss: 0.7414] [Real acc: 0.8125] [Fake acc: 0.5469]\n",
      "[Epoch 19/50] [D loss: 0.6347] [G loss: 0.8472] [D real acc: 0.6301] [D fake acc: 0.6466]\n",
      "[Epoch 20/50] [Batch 0/938] [D loss: 0.6149] [G loss: 1.0263] [Real acc: 0.5000] [Fake acc: 0.8281]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_g_loss = 0\n",
    "    epoch_d_loss = 0\n",
    "    epoch_real_acc = 0\n",
    "    epoch_fake_acc = 0\n",
    "    \n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "        current_batch_size = real_imgs.size(0)\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        real_label = torch.ones(current_batch_size, 1).to(device)\n",
    "        fake_label = torch.zeros(current_batch_size, 1).to(device)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        z = torch.randn(current_batch_size, latent_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        g_loss = adversarial_loss(discriminator(fake_imgs), real_label)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_preds = discriminator(real_imgs)\n",
    "        fake_preds = discriminator(fake_imgs.detach())\n",
    "\n",
    "        real_loss = adversarial_loss(real_preds, real_label)\n",
    "        fake_loss = adversarial_loss(fake_preds, fake_label)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        real_acc = ((real_preds > 0.5).float() == real_label).float().mean().item()\n",
    "        fake_acc = ((fake_preds > 0.5).float() == fake_label).float().mean().item()\n",
    "\n",
    "        epoch_g_loss += g_loss.item()\n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_real_acc += real_acc\n",
    "        epoch_fake_acc += fake_acc\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                  f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}] \"\n",
    "                  f\"[Real acc: {real_acc:.4f}] [Fake acc: {fake_acc:.4f}]\")\n",
    "\n",
    "    epoch_g_loss /= len(dataloader)\n",
    "    epoch_d_loss /= len(dataloader)\n",
    "    epoch_real_acc /= len(dataloader)\n",
    "    epoch_fake_acc /= len(dataloader)\n",
    "\n",
    "    g_losses.append(epoch_g_loss)\n",
    "    d_losses.append(epoch_d_loss)\n",
    "    real_accuracies.append(epoch_real_acc)\n",
    "    fake_accuracies.append(epoch_fake_acc)\n",
    "\n",
    "    print(f\"[Epoch {epoch}/{num_epochs}] \"\n",
    "          f\"[D loss: {epoch_d_loss:.4f}] [G loss: {epoch_g_loss:.4f}] \"\n",
    "          f\"[D real acc: {epoch_real_acc:.4f}] [D fake acc: {epoch_fake_acc:.4f}]\")\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            sample_z = torch.randn(25, latent_dim).to(device)\n",
    "            gen_imgs = generator(sample_z).cpu().detach()\n",
    "\n",
    "            fig, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "            for ax_i, ax in enumerate(axs.flat):\n",
    "                ax.imshow(gen_imgs[ax_i, 0].numpy(), cmap='gray')\n",
    "                ax.axis('off')\n",
    "            plt.savefig(f\"gan_generated_epoch_{epoch}.png\")\n",
    "            plt.close()\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(g_losses, label='Generator Loss')\n",
    "plt.plot(d_losses, label='Discriminator Loss')\n",
    "plt.title('GAN Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(real_accuracies, label='Real Accuracy')\n",
    "plt.plot(fake_accuracies, label='Fake Accuracy')\n",
    "plt.title('Discriminator Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gan_training_metrics.png\")\n",
    "plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_z = torch.randn(16, latent_dim).to(device)\n",
    "    gen_imgs = generator(sample_z).cpu().detach()\n",
    "\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(8, 8))\n",
    "    for ax_i, ax in enumerate(axs.flat):\n",
    "        ax.imshow(gen_imgs[ax_i, 0].numpy(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.savefig(\"final_gan_generated.png\")\n",
    "    plt.show()\n",
    "\n",
    "torch.save(generator.state_dict(), \"gan_generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"gan_discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
